# Home-Credit-Default-Risk
Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders.

# ğŸ¦ Home Credit Default Risk â€“ Kaggle Project  

## ğŸ“Œ Overview  
This project tackles the **Home Credit Default Risk** challenge from Kaggle.  
The goal is to predict whether a client will **repay (0)** or **default (1)** on a loan using demographic, financial, and historical credit data.  

By improving risk prediction, financial institutions like **Home Credit Group** can broaden financial inclusionâ€”approving more safe borrowers while reducing losses from defaults.  

---

## ğŸ”¹ Steps in the Project  
1. **Data Loading** â€“ Imported training & test datasets (`application_train.csv`, `application_test.csv`).  
2. **Preprocessing** â€“  
   - Removed ID columns  
   - One-hot encoded categorical variables  
   - Handled missing values with imputation  
   - Aligned train and test features  
3. **Baseline Model** â€“ Logistic Regression achieved **AUC ~0.62**.  
4. **Optimized Model** â€“ LightGBM achieved **AUC ~0.75** (stronger predictive power).  
5. **Feature Importance** â€“ Identified top predictors of default risk (e.g., external credit scores, age, employment history).  
6. **Predictions** â€“ Generated probability of default for each client and created a **Kaggle submission file**.  

---

## ğŸ“Š Results  
- **Logistic Regression AUC**: ~0.62 (baseline)  
- **LightGBM AUC**: ~0.75 (optimized)  
- **Insights**:  
  - Higher credit risk linked to weaker external credit scores and shorter employment histories  
  - Default rate in training data: ~8% (imbalanced dataset)  

---

## ğŸš€ Business Impact  
- Enables better loan approval strategies:  
  - **Low risk (<5%)** â†’ Approve normally âœ…  
  - **Medium risk (5â€“15%)** â†’ Approve with caution âš ï¸  
  - **High risk (>15%)** â†’ Reject or stricter terms âŒ  
- Helps Home Credit support **financial inclusion** while managing default risk.  

---

## ğŸ“‚ Files in Repository  
- `HomeCredit_Notebook.ipynb` â†’ Jupyter Notebook with full analysis & modeling  
- `submission.csv` â†’ Kaggle-ready predictions file  
- `README.md` â†’ Project documentation  

---

## ğŸ› ï¸ Tech Stack  
- **Python**  
- **Pandas, NumPy, Matplotlib, Seaborn**  
- **Scikit-learn** (Logistic Regression, preprocessing)  
- **LightGBM** (optimized model)  

---

## ğŸ“Œ Next Steps  
- Feature engineering with additional datasets (`bureau.csv`, `previous_application.csv`, `installments_payments.csv`)  
- Hyperparameter tuning with **Optuna/RandomSearch**  
- Handling class imbalance with **SMOTE / class weights**  
